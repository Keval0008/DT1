Below is the walkthrough script for the Data Reconciliation Tool, updated with a **Frequently Asked Questions (FAQ)** section tailored to anticipate common queries from users or stakeholders. The script remains concise and professional, designed for a 5-7 minute demo, with the FAQ section extending the presentation by 1-2 minutes if included. The walkthrough uses the test datasets (`original_data.xlsx` and `transformed_data.xlsx`) from previous responses and assumes the latest `app.py` implementation. The FAQs address technical, usability, and scalability questions based on the tool’s functionality and the issues encountered (e.g., multiple matches, pair addition).

---

### Walkthrough Script for Data Reconciliation Tool

**Introduction (30 seconds)**  
[Start with a greeting and context.]  
"Hello, everyone! I’m thrilled to demonstrate our Data Reconciliation Tool, a Dash-based application that simplifies comparing and validating datasets. Whether you’re reconciling financial records, customer data, or any tabular data, this tool automates column matching and anomaly detection to save time and ensure accuracy. Let’s walk through its features step-by-step!"

---

**Step 1: Overview of the Interface (1 minute)**  
[Open the dashboard at `http://localhost:8052` and describe the layout.]  
"Here’s the main interface of the Data Reconciliation Tool, built with Python, Dash, and Bootstrap for a clean, intuitive design. The layout is divided into three key sections:

1. **Upload Datasets**: Upload your original and transformed datasets here, in Excel or CSV format.  
2. **Column Matching**: Select and pair categorical and numerical columns, with sliders to fine-tune matching thresholds.  
3. **Debug Logs**: View real-time logs to troubleshoot issues.

Let’s start by uploading sample datasets to see the tool in action."

---

**Step 2: Uploading Datasets (1 minute)**  
[Demonstrate file uploads.]  
"I’m using two test files: `original_data.xlsx`, with columns like `Gender`, `Region`, and `Sales`, and `transformed_data.xlsx`, with similar columns renamed as `uppaded_gender`, `Sex`, and `Sales_Transformed`.

[Navigate to the ‘Upload Datasets’ section.]  
I’ll drag and drop `original_data.xlsx` into the ‘Original Dataset’ area. [Upload the file.] The status shows: ‘✅ original_data.xlsx (10 rows, 6 columns)’. Now, I’ll upload `transformed_data.xlsx`. [Upload the file.] And here: ‘✅ transformed_data.xlsx (5 rows, 6 columns)’."

[Point to dropdowns.]  
"Notice the dropdowns in the ‘Column Matching’ section. The ‘Categorical Source’ dropdown now lists `Gender` and `Region`, while ‘Numerical Source’ lists `Sales`. The transformed dropdowns show corresponding columns like `uppaded_gender` and `Sex`."

---

**Step 3: Column Matching and Multiple Matches (2 minutes)**  
[Show column matching and multiple-match handling.]  
"Let’s move to ‘Column Matching’. I’ll select `Gender` in the ‘Categorical Source’ dropdown. [Select `Gender`.] The tool uses Jaccard similarity to suggest matching columns from the transformed dataset, based on a default threshold of 0.1, adjustable here. [Point to the slider.]

[Point to ‘Categorical Transformed’ dropdown.]  
The ‘Categorical Transformed’ dropdown now lists `uppaded_gender (Similarity: 1.00)` and `Sex (Similarity: 1.00)`, indicating two perfect matches. The ‘Categorical Matches Info’ div confirms: ‘Multiple matches for 'Gender' with similarity 1.00: uppaded_gender, Sex’. This is great for cases where column names differ but data is identical.

By default, `uppaded_gender` is pre-selected. [Show selection.] I can switch to `Sex` if needed. [Select `Sex`.] I’ll adjust the threshold to 0.5 [move slider] to show how it filters lower-similarity matches, then set it back to 0.1."

---

**Step 4: Adding Column Pairs (1 minute)**  
[Demonstrate pair addition.]  
"Now, let’s pair columns for analysis. With `Gender` and `Sex` selected, I’ll click ‘Add Selected Pairs’. [Click the button.]

[Point to ‘Categorical Pairs Table’.]  
The table updates: `Gender → Sex`. I can remove this pair if needed. [Click the trash icon, then re-add if desired.] Let’s add a numerical pair. I’ll select `Sales` in ‘Numerical Source’, and the tool suggests `Sales_Transformed (Similarity: 1.00)’. [Select and click ‘Add Selected Pairs’.] The ‘Numerical Pairs Table’ shows: `Sales → Sales_Transformed`."

---

**Step 5: Performing Reconciliation Analysis (1.5 minutes)**  
[Run and explain the analysis.]  
"With our pairs set, let’s reconcile the data. I’ll click ‘Perform Reconciliation Analysis’. [Click the button.]

[Point to results.]  
The tool groups data by `Gender → Sex` and compares `Sales → Sales_Transformed` sums for each group. The results table shows original sums, transformed sums, and percentage differences, with anomalies highlighted in red if they exceed the 10% threshold. [Point to the slider.] Our test data is identical, so we see no anomalies, marked with a green checkmark. If discrepancies exist, they’d be flagged for review. I can adjust the anomaly threshold to be stricter or more lenient."

---

**Step 6: Debugging with Logs (30 seconds)**  
[Show the logs.]  
"For transparency, the ‘Debug Logs’ section shows real-time activity. [Scroll to logs.] Here, we see entries like ‘Successfully parsed original_data.xlsx’, ‘Suggested match for Gender: uppaded_gender’, and ‘Added 1 categorical pairs’. These logs help diagnose issues, especially with complex datasets."

---

**Step 7: Frequently Asked Questions (1-2 minutes)**  
[Address common questions to wrap up.]  
"Before we conclude, let me answer some frequently asked questions about the tool:

1. **What file formats are supported?**  
   The tool accepts CSV and Excel files, including `.xlsx`, `.xlsb`, `.xlsm`, and `.xls`. Ensure your data is tabular with clear column headers.

2. **How does the tool match columns?**  
   It uses Jaccard similarity for categorical columns, comparing unique values, and a multi-metric approach for numerical columns, including correlation and range overlap. Threshold sliders let you control match sensitivity.

3. **What if multiple columns match?**  
   As we saw with `Gender`, the tool detects multiple matches (e.g., `uppaded_gender` and `Sex`) and displays them with similarity scores. You can choose the desired match or let the tool suggest one.

4. **Can it handle large datasets?**  
   Yes, but for millions of rows, performance may depend on your hardware. We can optimize similarity calculations for larger datasets if needed.

5. **What if the datasets have different row counts?**  
   The tool handles mismatched row counts, as seen with our 10-row original and 5-row transformed datasets, by focusing on column-level similarities and grouped analysis.

6. **How can I troubleshoot issues?**  
   Use the debug logs to check for errors like file parsing issues or unmatched columns. The logs are saved to `app.log` for detailed review.

If you have more questions, I’d be happy to dive deeper!"

---

**Conclusion and Q&A (30 seconds)**  
[Wrap up and invite questions.]  
"That’s the Data Reconciliation Tool! It automates dataset comparison, handles complex matching scenarios, and delivers clear insights. Whether you’re auditing data or validating transformations, it’s a game-changer. Any questions or use cases you’d like to explore?"

---

### FAQs in Detail
For reference, here’s an expanded version of the FAQs with answers, which you can use for written documentation or to prepare for audience questions:

1. **What file formats are supported?**  
   **Answer**: The tool supports CSV and Excel files (`.xlsx`, `.xlsb`, `.xlsm`, `.xls`). Files must be tabular with defined column headers. Non-tabular formats (e.g., PDF, JSON) are not supported, but you can convert them to CSV/Excel first.

2. **How does the tool match columns?**  
   **Answer**: For categorical columns, it uses Jaccard similarity, calculating the overlap of unique values (e.g., `Gender` vs. `uppaded_gender`). For numerical columns, it combines metrics like Pearson correlation, range overlap, mean/std deviation similarity, and percentile differences. Thresholds (0.1 for categorical, 0.2 for numerical by default) filter matches, adjustable via sliders.

3. **What if multiple columns match?**  
   **Answer**: The tool detects multiple matches with near-identical similarity scores (within 0.001) and lists them in the transformed dropdown with scores (e.g., `uppaded_gender (Similarity: 1.00)`, `Sex (Similarity: 1.00)`). The ‘Matches Info’ div flags these cases, and the tool suggests the first match but allows manual selection.

4. **Can it handle large datasets?**  
   **Answer**: Yes, it processes datasets with thousands of rows efficiently. For millions of rows, similarity calculations may slow down, especially for numerical columns. Optimizations like sampling or parallel processing can be added for enterprise use.

5. **What if the datasets have different row counts?**  
   **Answer**: The tool handles differing row counts (e.g., 10 vs. 5 rows in your datasets) by focusing on column-level similarities and grouped analysis. Reconciliation compares sums within matching groups, and missing rows are treated as potential anomalies.

6. **How can I troubleshoot issues?**  
   **Answer**: Check the ‘Debug Logs’ section for real-time feedback on file uploads, matching, and errors. The `app.log` file provides detailed logs, including parsing errors or why pairs failed to add (e.g., mismatched source/transformed selections). Common issues include empty dropdowns (check file format) or unresponsive UI (check browser console for JavaScript errors).

7. **Can I export the reconciliation results?**  
   **Answer**: Currently, results are displayed in the UI. To export, you can extend the tool to save tables as CSV/Excel by adding a download button, which we can implement if needed.

8. **How do I adjust the sensitivity of anomaly detection?**  
   **Answer**: Use the ‘Anomaly Threshold’ slider (default 10%) to set the percentage difference for flagging anomalies. Lower values make the tool stricter, while higher values are more lenient.

---

### Notes for the Presenter
- **Preparation**:
  - Run `python app.py` and ensure the dashboard loads at `http://localhost:8052`.
  - Use the test datasets provided:
    ```python
    # original_data.xlsx
    import pandas as pd
    data = {
        'Gender': ['Male', 'Female', 'Male', 'Female', 'Other', 'Male', 'Female', 'Male', 'Female', 'Other'],
        'Region': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South'],
        'Sales': [100, 200, 150, 300, 250, 120, 180, 160, 290, 240],
        'Col3': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        'Col4': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],
        'Col5': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
    }
    df = pd.DataFrame(data)
    df.to_excel('original_data.xlsx', index=False)

    # transformed_data.xlsx
    data = {
        'uppaded_gender': ['Male', 'Female', 'Male', 'Female', 'Other'],
        'Sex': ['Male', 'Female', 'Male', 'Female', 'Other'],
        'Region': ['North', 'South', 'East', 'West', 'North'],
        'Sales_Transformed': [100, 200, 150, 300, 250],
        'Col3': [1, 2, 3, 4, 5],
        'Col4': ['A', 'B', 'C', 'D', 'E']
    }
    df = pd.DataFrame(data)
    df.to_excel('transformed_data.xlsx', index=False)
    ```
  - Clear `app.log` before the demo (`> app.log` on Unix or `echo. > app.log` on Windows).
  - Test all steps to ensure uploads, dropdowns, pair addition, and analysis work.

- **Timing**:
  - Main walkthrough: 5-7 minutes.
  - FAQ section: 1-2 minutes, adjustable based on audience interest.
  - Skip or shorten FAQs for time-constrained demos, or expand for technical audiences.

- **Visual Aids**:
  - Use a large screen or screen-sharing to highlight dropdowns, tables, and results.
  - Zoom in on key elements like the ‘Categorical Matches Info’ div or results table.

- **Troubleshooting**:
  - If uploads fail, verify file formats and check logs for parsing errors.
  - If pairs don’t add, ensure `categorical-transformed` has a selected value (e.g., `uppaded_gender` or `Sex`).
  - If the UI is unresponsive, check the browser console (F12) and `app.log` for errors.
  - Mention logs during the demo to show robustness: “If anything goes wrong, the logs will guide us.”

- **Customizing for Your Audience**:
  - **Technical Audience**: Emphasize Jaccard similarity, numerical metrics, and log debugging. Mention the Python/Dash backend.
  - **Non-Technical Audience**: Focus on ease of use, visual outputs, and practical benefits (e.g., catching data errors).
  - **Your Datasets**: If using your own data, replace `Gender`, `Sex`, `Sales`, etc., with actual column names in the script. Share column names if you need a tailored script.

- **Extending the Demo**:
  - If time allows, demonstrate changing the anomaly threshold or removing/re-adding pairs.
  - For advanced users, show how logs track every action (e.g., open `app.log` in a text editor).

---

### Testing the Walkthrough
1. Run the app and test all steps with the provided datasets.
2. Verify:
   - Uploads show correct file info.
   - Selecting `Gender` populates `uppaded_gender` and `Sex` with similarity scores.
   - `Categorical Matches Info` shows multiple matches.
   - Clicking ‘Add Selected Pairs’ updates the table.
   - Reconciliation analysis displays results without errors.
3. Check `app.log` for entries like:
   ```
   2025-08-04 ... - INFO - Added 1 categorical pairs
   2025-08-04 ... - INFO - Multiple matches for Gender: [('uppaded_gender', 1.0), ('Sex', 1.0)]
   ```
4. Practice the script to stay within 5-7 minutes (or 7-9 with FAQs).

If you need a tailored script (e.g., specific column names, shorter/longer duration, or additional features like exporting results), or if you encounter issues during testing, please provide:
- Column names and sample rows of your datasets.
- Audience details (technical level, size).
- Time constraints or specific demo goals.
- Any errors or logs from testing.

Let me know if you’d like a slide deck outline, a video script format, or further assistance with the presentation!                            'fontSize': '14px'
                        },
                        multiple=False
                    ),
                    html.Div(id='original-file-info', className="text-muted small mt-2")
                ], md=6),
                dbc.Col([
                    html.H5("Transformed Dataset", className="mb-2"),
                    dcc.Upload(
                        id='upload-transformed',
                        children=html.Div([
                            '📁 Drag and Drop or ',
                            html.A('Select File', style={'color': '#3498db', 'textDecoration': 'underline'})
                        ]),
                        style={
                            'width': '100%',
                            'height': '50px',
                            'lineHeight': '50px',
                            'borderWidth': '2px',
                            'borderStyle': 'dashed',
                            'borderRadius': '8px',
                            'textAlign': 'center',
                            'margin': '5px 0',
                            'backgroundColor': '#f8f9fa',
                            'borderColor': '#dee2e6',
                            'color': '#6c757d',
                            'fontSize': '14px'
                        },
                        multiple=False
                    ),
                    html.Div(id='transformed-file-info', className="text-muted small mt-2")
                ], md=6),
            ]),
        ])
    ], className="mb-4"),
    
    # Column selection section
    html.Div([
        html.H3("Column Matching", className="mb-3"),
        dbc.Card([
            dbc.CardBody([
                html.H5("🎯 Matching Thresholds", className="mb-3"),
                dbc.Row([
                    dbc.Col([
                        html.Label("Categorical Threshold:", className="fw-bold small mb-1"),
                        dcc.Slider(
                            id='categorical-threshold',
                            min=0.0,
                            max=1.0,
                            step=0.05,
                            value=0.1,
                            marks={0.0: '0.0', 0.25: '0.25', 0.5: '0.5', 0.75: '0.75', 1.0: '1.0'},
                            tooltip={"placement": "bottom", "always_visible": True}
                        ),
                        html.Div(id='categorical-threshold-display', className="text-muted small mt-1")
                    ], md=4),
                    dbc.Col([
                        html.Label("Numerical Threshold:", className="fw-bold small mb-1"),
                        dcc.Slider(
                            id='numerical-threshold',
                            min=0.0,
                            max=1.0,
                            step=0.05,
                            value=0.2,
                            marks={0.0: '0.0', 0.25: '0.25', 0.5: '0.5', 0.75: '0.75', 1.0: '1.0'},
                            tooltip={"placement": "bottom", "always_visible": True}
                        ),
                        html.Div(id='numerical-threshold-display', className="text-muted small mt-1")
                    ], md=4),
                    dbc.Col([
                        html.Label("Anomaly Threshold (%):", className="fw-bold small mb-1"),
                        dcc.Slider(
                            id='anomaly-threshold',
                            min=0.0,
                            max=50.0,
                            step=1.0,
                            value=10.0,
                            marks={0.0: '0%', 10.0: '10%', 20.0: '20%', 30.0: '30%', 50.0: '50%'},
                            tooltip={"placement": "bottom", "always_visible": True}
                        ),
                        html.Div(id='anomaly-threshold-display', className="text-muted small mt-1")
                    ], md=4),
                ])
            ])
        ], className="mb-3"),
        
        dbc.Row([
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H4("📊 Categorical Columns", className="mb-3"),
                        html.Label("Select Source Columns:", className="fw-bold small mb-1"),
                        dcc.Dropdown(
                            id='categorical-source',
                            options=[],
                            multi=True,
                            placeholder="Select categorical columns...",
                            className="mb-2"
                        ),
                        html.Div(id='categorical-matches-text', className="text-muted small mb-2"),  # Add this line
                        html.Label("Select Transformed Columns:", className="fw-bold small mb-1"),
                        dcc.Dropdown(
                            id='categorical-transformed',
                            options=[],
                            multi=True,
                            placeholder="Select transformed columns...",
                            className="mb-2"
                        ),
                        html.Button("Add Selected Pairs", id='add-categorical-pairs', className="btn btn-primary btn-sm mb-2"),
                        html.Div(id='categorical-pairs-table', children=[])
                    ])
                ])
            ], md=6),
            dbc.Col([
                dbc.Card([
                    dbc.CardBody([
                        html.H4("🔢 Numerical Columns", className="mb-3"),
                        html.Label("Select Source Columns:", className="fw-bold small mb-1"),
                        dcc.Dropdown(
                            id='numerical-source',
                            options=[],
                            multi=True,
                            placeholder="Select numerical columns...",
                            className="mb-2"
                        ),
                        html.Div(id='numerical-matches-text', className="text-muted small mb-2"),  # Add this line
                        html.Label("Select Transformed Columns:", className="fw-bold small mb-1"),
                        dcc.Dropdown(
                            id='numerical-transformed',
                            options=[],
                            multi=True,
                            placeholder="Select transformed columns...",
                            className="mb-2"
                        ),
                        html.Button("Add Selected Pairs", id='add-numerical-pairs', className="btn btn-success btn-sm mb-2"),
                        html.Div(id='numerical-pairs-table', children=[])
                    ])
                ])
            ], md=6),
        ], className="mb-4"),
        
        html.Div([
            dbc.Button("🔍 Perform Reconciliation Analysis", id='display-data-btn',
                      color="info", size="lg", className="mb-3"),
            html.Div(id='display-results', children=[])
        ], className="text-center")
    ], id='main-selection-area', className="mb-4"),
    
    # Log display section
    dbc.Card([
        dbc.CardBody([
            html.H5("Debug Logs", className="mb-3"),
            dcc.Interval(id='log-update-interval', interval=1000, n_intervals=0),
            html.Pre(id='log-display', style={
                'maxHeight': '200px',
                'overflowY': 'auto',
                'backgroundColor': '#f8f9fa',
                'padding': '10px',
                'borderRadius': '5px',
                'fontSize': '12px'
            })
        ])
    ], className="mb-4"),
    
    # Store components
    dcc.Store(id='original-data-store'),
    dcc.Store(id='transformed-data-store'),
    dcc.Store(id='selection-pairs', data={'categorical': [], 'numerical': []})
], className="container-fluid py-4")

def parse_contents(contents, filename):
    """Parse uploaded file contents"""
    logger.info(f"Parsing file: {filename}")
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    
    try:
        if 'csv' in filename.lower():
            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        elif any(ext in filename.lower() for ext in ['xlsx', 'xlsb', 'xlsm', 'xls']):
            df = pd.read_excel(io.BytesIO(decoded))
        else:
            logger.error(f"Unsupported file type: {filename}")
            return None
        logger.info(f"Successfully parsed {filename}: {len(df)} rows, {len(df.columns)} columns")
        return df
    except Exception as e:
        logger.error(f"Error parsing file {filename}: {str(e)}")
        return None

def jaccard_similarity(set1, set2):
    """Calculate Jaccard similarity between two sets"""
    if len(set1) == 0 and len(set2) == 0:
        return 1.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0.0

def calculate_numerical_similarity(source_series, target_series):
    """Calculate similarity between two numerical series"""
    source_clean = source_series.dropna()
    target_clean = target_series.dropna()
    
    if len(source_clean) == 0 or len(target_clean) == 0:
        logger.warning("Empty data in numerical similarity calculation")
        return 0.0
    
    similarities = []
    
    try:
        if len(source_clean) > 1 and len(target_clean) > 1:
            min_len = min(len(source_clean), len(target_clean))
            if min_len > 1:
                source_sample = source_clean.iloc[:min_len]
                target_sample = target_clean.iloc[:min_len]
                correlation = abs(np.corrcoef(source_sample, target_sample)[0, 1])
                if not np.isnan(correlation):
                    similarities.append(correlation)
    except Exception as e:
        logger.error(f"Error in correlation calculation: {str(e)}")
    
    try:
        source_min, source_max = source_clean.min(), source_clean.max()
        target_min, target_max = target_clean.min(), target_clean.max()
        
        if source_min == source_max and target_min == target_max:
            range_sim = 1.0 if source_min == target_min else 0.0
        else:
            overlap_min = max(source_min, target_min)
            overlap_max = min(source_max, target_max)
            
            if overlap_max > overlap_min:
                overlap_range = overlap_max - overlap_min
                source_range = max(source_max - source_min, 1e-10)
                target_range = max(target_max - target_min, 1e-10)
                total_range = max(source_range, target_range)
                range_sim = overlap_range / total_range
            else:
                range_sim = 0.0
        similarities.append(range_sim)
    except Exception as e:
        logger.error(f"Error in range similarity calculation: {str(e)}")
    
    try:
        source_mean, source_std = source_clean.mean(), source_clean.std()
        target_mean, target_std = target_clean.mean(), target_clean.std()
        
        data_range = max(abs(source_mean), abs(target_mean), source_std, target_std, 1e-10)
        mean_diff = abs(source_mean - target_mean) / data_range
        mean_sim = max(0, 1 - mean_diff)
        
        if source_std == 0 and target_std == 0:
            std_sim = 1.0
        else:
            max_std = max(source_std, target_std, 1e-10)
            std_diff = abs(source_std - target_std) / max_std
            std_sim = max(0, 1 - std_diff)
        
        dist_sim = (mean_sim + std_sim) / 2
        similarities.append(dist_sim)
    except Exception as e:
        logger.error(f"Error in distribution similarity calculation: {str(e)}")
    
    try:
        source_percentiles = np.percentile(source_clean, [25, 50, 75])
        target_percentiles = np.percentile(target_clean, [25, 50, 75])
        
        percentile_sims = []
        for sp, tp in zip(source_percentiles, target_percentiles):
            if sp == 0 and tp == 0:
                percentile_sims.append(1.0)
            else:
                max_val = max(abs(sp), abs(tp), 1e-10)
                diff = abs(sp - tp) / max_val
                percentile_sims.append(max(0, 1 - diff))
        
        percentile_sim = np.mean(percentile_sims)
        similarities.append(percentile_sim)
    except Exception as e:
        logger.error(f"Error in percentile similarity calculation: {str(e)}")
    
    try:
        source_unique = len(source_clean.unique())
        target_unique = len(target_clean.unique())
        
        if source_unique <= 20 and target_unique <= 20:
            source_values = set(source_clean.round(6))
            target_values = set(target_clean.round(6))
            overlap_sim = jaccard_similarity(source_values, target_values)
            similarities.append(overlap_sim)
    except Exception as e:
        logger.error(f"Error in overlap similarity calculation: {str(e)}")
    
    return np.mean(similarities) if similarities else 0.0

def find_matching_columns(source_column_data, target_df, column_type='categorical', categorical_threshold=0.1, numerical_threshold=0.2):
    """Find matching columns in target dataframe for a given source column"""
    logger.info(f"Finding matches for column type: {column_type}, thresholds: categorical={categorical_threshold}, numerical={numerical_threshold}")
    matches = []
    
    if column_type == 'categorical':
        target_columns = target_df.select_dtypes(include=['object', 'category']).columns
        source_values = set(source_column_data.dropna().astype(str))
        
        for col in target_columns:
            target_values = set(target_df[col].dropna().astype(str))
            similarity = jaccard_similarity(source_values, target_values)
            
            if similarity >= categorical_threshold:
                matches.append((col, similarity))
                logger.debug(f"Categorical match: {col} (similarity: {similarity:.2f})")
                
    else:
        target_columns = target_df.select_dtypes(include=[np.number]).columns
        for col in target_columns:
            similarity = calculate_numerical_similarity(source_column_data, target_df[col])
            if similarity >= numerical_threshold:
                matches.append((col, similarity))
                logger.debug(f"Numerical match: {col} (similarity: {similarity:.2f})")
    
    matches.sort(key=lambda x: x[1], reverse=True)
    logger.info(f"Found {len(matches)} matches: {matches}")
    return matches

@app.callback(
    [Output('original-data-store', 'data'),
     Output('transformed-data-store', 'data'),
     Output('original-file-info', 'children'),
     Output('transformed-file-info', 'children'),
     Output('categorical-source', 'options'),
     Output('numerical-source', 'options'),
     Output('categorical-transformed', 'options'),
     Output('numerical-transformed', 'options')],
    [Input('upload-original', 'contents'),
     Input('upload-transformed', 'contents')],
    [State('upload-original', 'filename'),
     State('upload-transformed', 'filename')]
)
def update_output(original_contents, transformed_contents, original_filename, transformed_filename):
    """Handle file uploads and update data stores and dropdown options"""
    logger.info("Entering update_output callback")
    original_uploaded = original_contents is not None
    transformed_uploaded = transformed_contents is not None
    
    original_file_info = ""
    transformed_file_info = ""
    cat_source_options = []
    num_source_options = []
    cat_trans_options = []
    num_trans_options = []
    
    global original_data, transformed_data
    
    if original_uploaded:
        original_data = parse_contents(original_contents, original_filename)
        if original_data is not None:
            original_file_info = f"✅ {original_filename} ({len(original_data)} rows, {len(original_data.columns)} columns)"
            logger.info(f"Original data uploaded: {original_filename}")
            cat_source_options = [{'label': col, 'value': col} for col in 
                                original_data.select_dtypes(include=['object', 'category']).columns]
            num_source_options = [{'label': col, 'value': col} for col in 
                                original_data.select_dtypes(include=[np.number]).columns]
        else:
            original_file_info = f"❌ {original_filename} - Error reading file"
    
    if transformed_uploaded:
        transformed_data = parse_contents(transformed_contents, transformed_filename)
        if transformed_data is not None:
            transformed_file_info = f"✅ {transformed_filename} ({len(transformed_data)} rows, {len(transformed_data.columns)} columns)"
            logger.info(f"Transformed data uploaded: {transformed_filename}")
            cat_trans_options = [{'label': col, 'value': col} for col in 
                               transformed_data.select_dtypes(include=['object', 'category']).columns]
            num_trans_options = [{'label': col, 'value': col} for col in 
                               transformed_data.select_dtypes(include=[np.number]).columns]
        else:
            transformed_file_info = f"❌ {transformed_filename} - Error reading file"
    
    original_json = original_data.to_json(date_format='iso', orient='split') if original_data is not None else None
    transformed_json = transformed_data.to_json(date_format='iso', orient='split') if transformed_data is not None else None
    
    logger.info("Exiting update_output callback")
    return (original_json, transformed_json, original_file_info, transformed_file_info,
            cat_source_options, num_source_options, cat_trans_options, num_trans_options)

@app.callback(
    [Output('categorical-transformed', 'value'),
     Output('numerical-transformed', 'value')],
    [Input('categorical-source', 'value'),
     Input('numerical-source', 'value'),
     Input('categorical-threshold', 'value'),
     Input('numerical-threshold', 'value')],
    [State('original-data-store', 'data'),
     State('transformed-data-store', 'data'),
     State('categorical-transformed', 'options'),
     State('numerical-transformed', 'options')]
)
def suggest_transformed_columns(cat_source_cols, num_source_cols, cat_threshold, num_threshold, 
                              original_json, transformed_json, cat_trans_options, num_trans_options):
    """Suggest transformed columns based on source column selections"""
    logger.info(f"Entering suggest_transformed_columns callback, cat_source_cols={cat_source_cols}, num_source_cols={num_source_cols}")
    
    cat_trans_values = []
    num_trans_values = []
    
    if not original_json or not transformed_json:
        logger.warning("Missing datasets, no suggestions possible")
        return [], []
    
    original_df = pd.read_json(original_json, orient='split')
    transformed_df = pd.read_json(transformed_json, orient='split')
    
    # Suggest categorical matches
    if cat_source_cols:
        for col in cat_source_cols:
            if col in original_df.columns:
                matches = find_matching_columns(original_df[col], transformed_df, 'categorical', 
                                              categorical_threshold=cat_threshold)
                # Prefer exact match (same column name) or highest similarity
                if col in transformed_df.columns and jaccard_similarity(
                    set(original_df[col].dropna().astype(str)),
                    set(transformed_df[col].dropna().astype(str))
                ) >= 0.9:
                    cat_trans_values.append(col)
                    logger.info(f"Suggested exact match for categorical column {col}: {col}")
                elif matches:
                    cat_trans_values.append(matches[0][0])
                    logger.info(f"Suggested match for categorical column {col}: {matches[0][0]} ({matches[0][1]:.2f})")
    
    # Suggest numerical matches
    if num_source_cols:
        for col in num_source_cols:
            if col in original_df.columns:
                matches = find_matching_columns(original_df[col], transformed_df, 'numerical', 
                                              numerical_threshold=num_threshold)
                if col in transformed_df.columns and pd.api.types.is_numeric_dtype(transformed_df[col]) and calculate_numerical_similarity(
                    original_df[col], transformed_df[col]
                ) >= 0.8:
                    num_trans_values.append(col)
                    logger.info(f"Suggested exact match for numerical column {col}: {col}")
                elif matches:
                    num_trans_values.append(matches[0][0])
                    logger.info(f"Suggested match for numerical column {col}: {matches[0][0]} ({matches[0][1]:.2f})")
    
    logger.info(f"Suggested categorical matches: {cat_trans_values}")
    logger.info(f"Suggested numerical matches: {num_trans_values}")
    return cat_trans_values, num_trans_values

@app.callback(
    [Output('categorical-pairs-table', 'children'),
     Output('numerical-pairs-table', 'children'),
     Output('selection-pairs', 'data')],
    [Input('add-categorical-pairs', 'n_clicks'),
     Input('add-numerical-pairs', 'n_clicks'),
     Input({'type': 'remove-pair', 'index': ALL, 'category': ALL}, 'n_clicks')],
    [State('categorical-source', 'value'),
     State('categorical-transformed', 'value'),
     State('numerical-source', 'value'),
     State('numerical-transformed', 'value'),
     State('selection-pairs', 'data')]
)
def update_selection_pairs(cat_add_clicks, num_add_clicks, remove_clicks, 
                         cat_source, cat_trans, num_source, num_trans, selection_pairs):
    """Update the selection pairs and display tables"""
    logger.info(f"Entering update_selection_pairs callback, cat_add_clicks={cat_add_clicks}, num_add_clicks={num_add_clicks}")
    logger.debug(f"Current selection_pairs: {json.dumps(selection_pairs, indent=2)}")
    
    ctx = callback_context
    selection_pairs = selection_pairs or {'categorical': [], 'numerical': []}
    cat_pairs = selection_pairs.get('categorical', [])
    num_pairs = selection_pairs.get('numerical', [])
    
    if not ctx.triggered:
        logger.info("No trigger in update_selection_pairs")
        return [], [], selection_pairs
    
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0]
    
    if triggered_id == 'add-categorical-pairs':
        if cat_source and cat_trans and len(cat_source) == len(cat_trans):
            new_pairs = [{'id': str(uuid.uuid4()), 'source': src, 'transformed': trans} 
                        for src, trans in zip(cat_source, cat_trans)]
            cat_pairs.extend(new_pairs)
            logger.info(f"Added {len(new_pairs)} categorical pairs")
    
    elif triggered_id == 'add-numerical-pairs':
        if num_source and num_trans and len(num_source) == len(num_trans):
            new_pairs = [{'id': str(uuid.uuid4()), 'source': src, 'transformed': trans} 
                        for src, trans in zip(num_source, num_trans)]
            num_pairs.extend(new_pairs)
            logger.info(f"Added {len(new_pairs)} numerical pairs")
    
    else:
        try:
            button_id = json.loads(triggered_id.replace("'", '"'))
            pair_id = button_id['index']
            category = button_id['category']
            if category == 'categorical':
                cat_pairs = [pair for pair in cat_pairs if pair['id'] != pair_id]
                logger.info(f"Removed categorical pair with ID: {pair_id}")
            elif category == 'numerical':
                num_pairs = [pair for pair in num_pairs if pair['id'] != pair_id]
                logger.info(f"Removed numerical pair with ID: {pair_id}")
        except Exception as e:
            logger.error(f"Error parsing remove button ID: {str(e)}")
    
    selection_pairs['categorical'] = cat_pairs
    selection_pairs['numerical'] = num_pairs
    
    # Create tables for display
    cat_table = dbc.Table([
        html.Thead(html.Tr([
            html.Th("Source Column"),
            html.Th("Transformed Column"),
            html.Th("Action")
        ])),
        html.Tbody([
            html.Tr([
                html.Td(pair['source']),
                html.Td(pair['transformed']),
                html.Td(dbc.Button("🗑️", id={'type': 'remove-pair', 'index': pair['id'], 'category': 'categorical'},
                                  color="danger", size="sm"))
            ]) for pair in cat_pairs
        ])
    ], bordered=True, hover=True, responsive=True, size="sm") if cat_pairs else html.Div("No categorical pairs selected.")
    
    num_table = dbc.Table([
        html.Thead(html.Tr([
            html.Th("Source Column"),
            html.Th("Transformed Column"),
            html.Th("Action")
        ])),
        html.Tbody([
            html.Tr([
                html.Td(pair['source']),
                html.Td(pair['transformed']),
                html.Td(dbc.Button("🗑️", id={'type': 'remove-pair', 'index': pair['id'], 'category': 'numerical'},
                                  color="danger", size="sm"))
            ]) for pair in num_pairs
        ])
    ], bordered=True, hover=True, responsive=True, size="sm") if num_pairs else html.Div("No numerical pairs selected.")
    
    logger.debug(f"Updated selection_pairs: {json.dumps(selection_pairs, indent=2)}")
    return cat_table, num_table, selection_pairs

@app.callback(
    Output('categorical-threshold-display', 'children'),
    [Input('categorical-threshold', 'value')]
)
def update_categorical_threshold_display(value):
    """Update categorical threshold display"""
    logger.info(f"Updating categorical threshold display: {value}")
    return f"Current threshold: {value:.2f}"

@app.callback(
    Output('numerical-threshold-display', 'children'),
    [Input('numerical-threshold', 'value')]
)
def update_numerical_threshold_display(value):
    """Update numerical threshold display"""
    logger.info(f"Updating numerical threshold display: {value}")
    return f"Current threshold: {value:.2f}"

@app.callback(
    Output('anomaly-threshold-display', 'children'),
    [Input('anomaly-threshold', 'value')]
)
def update_anomaly_threshold_display(value):
    """Update anomaly threshold display"""
    logger.info(f"Updating anomaly threshold display: {value}")
    return f"Current threshold: {value:.1f}%"

@app.callback(
    Output('log-display', 'children'),
    [Input('log-update-interval', 'n_intervals')]
)
def update_log_display(n_intervals):
    """Update the log display in the UI"""
    try:
        with open('app.log', 'r') as log_file:
            logs = log_file.read()
        return logs
    except Exception as e:
        logger.error(f"Error reading log file: {str(e)}")
        return "Error reading logs"

@app.callback(
    Output('display-results', 'children'),
    [Input('display-data-btn', 'n_clicks')],
    [State('selection-pairs', 'data'),
     State('original-data-store', 'data'),
     State('transformed-data-store', 'data'),
     State('anomaly-threshold', 'value')]
)
def perform_reconciliation_analysis(n_clicks, selection_pairs, original_json, transformed_json, anomaly_threshold):
    """Perform comprehensive data reconciliation analysis"""
    logger.info(f"Entering perform_reconciliation_analysis callback, n_clicks={n_clicks}")
    logger.debug(f"Current selection_pairs: {json.dumps(selection_pairs, indent=2)}")
    
    if n_clicks is None or not original_json or not transformed_json:
        logger.warning("Missing inputs for reconciliation analysis")
        return []
    
    try:
        original_df = pd.read_json(original_json, orient='split')
        transformed_df = pd.read_json(transformed_json, orient='split')
        
        selection_pairs = selection_pairs or {'categorical': [], 'numerical': []}
        cat_pairs = selection_pairs.get('categorical', [])
        num_pairs = selection_pairs.get('numerical', [])
        
        categorical_columns = [pair['source'] for pair in cat_pairs]
        categorical_matches = [pair['transformed'] for pair in cat_pairs]
        numerical_columns = [pair['source'] for pair in num_pairs]
        numerical_matches = [pair['transformed'] for pair in num_pairs]
        
        logger.info(f"Categorical columns: {categorical_columns}, matches: {categorical_matches}")
        logger.info(f"Numerical columns: {numerical_columns}, matches: {numerical_matches}")
        
        warnings = []
        
        if categorical_columns and not any(categorical_matches):
            warnings.append("⚠️ Warning: Categorical columns selected but no matches found in transformed data")
            logger.warning("No categorical matches found")
        
        if numerical_columns and not any(numerical_matches):
            warnings.append("⚠️ Warning: Numerical columns selected but no matches found in transformed data")
            logger.warning("No numerical matches found")
        
        missing_original_cat = [col for col in categorical_columns if col not in original_df.columns]
        missing_original_num = [col for col in numerical_columns if col not in original_df.columns]
        missing_transformed_cat = [col for col in categorical_matches if col and col not in transformed_df.columns]
        missing_transformed_num = [col for col in numerical_matches if col and col not in transformed_df.columns]
        
        if missing_original_cat:
            warnings.append(f"⚠️ Warning: Categorical columns not found in original data: {missing_original_cat}")
            logger.warning(f"Missing original categorical columns: {missing_original_cat}")
        if missing_original_num:
            warnings.append(f"⚠️ Warning: Numerical columns not found in original data: {missing_original_num}")
            logger.warning(f"Missing original numerical columns: {missing_original_num}")
        if missing_transformed_cat:
            warnings.append(f"⚠️ Warning: Categorical columns not found in transformed data: {missing_transformed_cat}")
            logger.warning(f"Missing transformed categorical columns: {missing_transformed_cat}")
        if missing_transformed_num:
            warnings.append(f"⚠️ Warning: Numerical columns not found in transformed data: {missing_transformed_num}")
            logger.warning(f"Missing transformed numerical columns: {missing_transformed_num}")
        
        available_cat_original = [col for col in categorical_columns if col in original_df.columns]
        available_cat_transformed = [col for col in categorical_matches if col and col in transformed_df.columns]
        available_num_original = [col for col in numerical_columns if col in original_df.columns]
        available_num_transformed = [col for col in numerical_matches if col and col in transformed_df.columns]
        
        if not available_cat_original and not available_num_original:
            logger.warning("No valid columns selected for analysis")
            return html.Div("No valid columns selected for analysis.", 
                           style={'color': '#6c757d', 'textAlign': 'center', 'margin': '20px 0'})
        
        analysis_results = []
        
        for orig_num_col, trans_num_col in zip(available_num_original, available_num_transformed):
            try:
                logger.info(f"Analyzing numerical pair: {orig_num_col} -> {trans_num_col}")
                if available_cat_original and available_cat_transformed and len(available_cat_original) == len(available_cat_transformed):
                    original_grouped = original_df.groupby(available_cat_original)[orig_num_col].sum().reset_index()
                    transformed_grouped = transformed_df.groupby(available_cat_transformed)[trans_num_col].sum().reset_index()
                    
                    original_grouped.columns = [f"orig_{col}" if col != orig_num_col else "orig_sum" for col in original_grouped.columns]
                    transformed_grouped.columns = [f"trans_{col}" if col != trans_num_col else "trans_sum" for col in transformed_grouped.columns]
                    
                    comparison_df = pd.merge(original_grouped, transformed_grouped, 
                                           left_on=[f"orig_{col}" for col in available_cat_original],
                                           right_on=[f"trans_{col}" for col in available_cat_transformed],
                                           how='outer')
                    
                    comparison_df['percentage_diff'] = np.where(
                        (comparison_df['orig_sum'].notna()) & (comparison_df['trans_sum'].notna()),
                        abs(comparison_df['orig_sum'] - comparison_df['trans_sum']) / comparison_df['orig_sum'] * 100,
                        np.nan
                    )
                    
                    anomalies = comparison_df[comparison_df['percentage_diff'] > anomaly_threshold]
                    
                    analysis_result = {
                        'numerical_column': f"{orig_num_col} → {trans_num_col}",
                        'categorical_columns': f"{' + '.join(f'{orig} → {trans}' for orig, trans in zip(available_cat_original, available_cat_transformed))}",
                        'total_groups': len(comparison_df),
                        'anomalies': len(anomalies),
                        'anomaly_percentage': len(anomalies) / len(comparison_df) * 100 if len(comparison_df) > 0 else 0,
                        'comparison_data': comparison_df,
                        'anomalies_data': anomalies
                    }
                    
                    analysis_results.append(analysis_result)
                    logger.info(f"Completed analysis for {orig_num_col}, found {len(anomalies)} anomalies")
                else:
                    orig_total = original_df[orig_num_col].sum()
                    trans_total = transformed_df[trans_num_col].sum()
                    percentage_diff = abs(orig_total - trans_total) / orig_total * 100 if orig_total != 0 else 0
                    
                    comparison_df = pd.DataFrame({
                        'orig_sum': [orig_total],
                        'trans_sum': [trans_total],
                        'percentage_diff': [percentage_diff]
                    })
                    
                    analysis_result = {
                        'numerical_column': f"{orig_num_col} → {trans_num_col}",
                        'categorical_columns': "No grouping (totals comparison)",
                        'total_groups': 1,
                        'anomalies': 1 if percentage_diff > anomaly_threshold else 0,
                        'anomaly_percentage': percentage_diff,
                        'comparison_data': comparison_df,
                        'orig_total': orig_total,
                        'trans_total': trans_total,
                        'percentage_diff': percentage_diff
                    }
                    
                    analysis_results.append(analysis_result)
                    logger.info(f"Completed totals comparison for {orig_num_col}, percentage_diff={percentage_diff:.2f}%")
                
            except Exception as e:
                logger.error(f"Error analyzing {orig_num_col} -> {trans_num_col}: {str(e)}")
                analysis_results.append({
                    'numerical_column': f"{orig_num_col} → {trans_num_col}",
                    'error': str(e)
                })
        
        display_components = []
        
        if warnings:
            warning_card = dbc.Card([
                dbc.CardBody([
                    html.H5("⚠️ Warnings", className="text-warning mb-3"),
                    html.Ul([html.Li(warning) for warning in warnings])
                ])
            ], className="mb-3")
            display_components.append(warning_card)
        
        for result in analysis_results:
            if 'error' in result:
                error_card = dbc.Card([
                    dbc.CardBody([
                        html.H5(f"❌ Analysis Error: {result['numerical_column']}", className="text-danger mb-2"),
                        html.P(f"Error: {result['error']}", className="text-muted")
                    ])
                ], className="mb-3")
                display_components.append(error_card)
            else:
                status_color = "success" if result['anomalies'] == 0 else "danger"
                status_icon = "✅" if result['anomalies'] == 0 else "❌"
                
                has_comparison_data = 'comparison_data' in result
                
                analysis_card = dbc.Card([
                    dbc.CardBody([
                        html.H5(f"{status_icon} {result['numerical_column']}", className=f"text-{status_color} mb-3"),
                        html.P(f"<strong>Categorical Grouping:</strong> {result['categorical_columns']}", className="mb-2"),
                        html.P(f"<strong>Total Groups:</strong> {result['total_groups']}", className="mb-1"),
                        html.P(f"<strong>Anomalies Found:</strong> {result['anomalies']} ({result['anomaly_percentage']:.1f}%)", className="mb-1"),
                        html.P(f"<strong>Anomaly Threshold:</strong> {anomaly_threshold:.1f}%", className="mb-1"),
                        
                        html.Div([
                            html.H6("Data Comparison:", className="mt-3 mb-2"),
                            dbc.Table([
                                html.Thead(html.Tr([
                                    *([html.Th(col.replace('orig_', '').replace('trans_', ''), style={'backgroundColor': '#e9ecef', 'fontWeight': 'bold'}) for col in result['comparison_data'].columns if col.startswith('orig_') and not col == 'orig_sum']),
                                    html.Th("Original Sum"),
                                    html.Th("Transformed Sum"),
                                    html.Th("Difference (%)")
                                ])),
                                html.Tbody([
                                    html.Tr([
                                        *([html.Td(str(row[col]), style={'backgroundColor': '#f8f9fa', 'fontWeight': '500'}) for col in result['comparison_data'].columns if col.startswith('orig_') and not col == 'orig_sum']),
                                        html.Td(f"{row['orig_sum']:,.2f}"),
                                        html.Td(f"{row['trans_sum']:,.2f}"),
                                        html.Td(f"{row['percentage_diff']:.2f}%", 
                                               style={'color': '#dc3545' if row['percentage_diff'] > anomaly_threshold else 'inherit',
                                                      'fontWeight': 'bold' if row['percentage_diff'] > anomaly_threshold else 'normal'})
                                    ], style={'backgroundColor': '#f8d7da' if row['percentage_diff'] > anomaly_threshold else 'inherit'}) 
                                    for _, row in result['comparison_data'].iterrows()
                                ])
                            ], bordered=True, hover=True, responsive=True, size="sm")
                        ]) if has_comparison_data else html.Div("❌ No comparison data available", className="text-danger mt-2")
                    ])
                ], className="mb-3")
                display_components.append(analysis_card)
        
        if analysis_results:
            # Create Excel file
            excel_file = generate_excel_from_results(analysis_results, anomaly_threshold)
            
            # Add download button
            download_card = dbc.Card([
                dbc.CardBody([
                    html.H5("📥 Download Results", className="mb-3"),
                    dcc.Download(id="download-analysis"),
                    dbc.Button(
                        "Download Analysis Results (XLSX)",
                        id="download-button",
                        color="success",
                        className="w-100"
                    )
                ])
            ], className="mb-3")
            
            display_components.append(download_card)
        
        logger.info("Completed reconciliation analysis")
        return display_components
    except Exception as e:
        logger.error(f"Error in perform_reconciliation_analysis: {str(e)}")
        raise

# Modify the download_analysis_results callback
@app.callback(
    Output("download-analysis", "data"),
    Input("download-button", "n_clicks"),
    [State('selection-pairs', 'data'),
     State('original-data-store', 'data'),
     State('transformed-data-store', 'data'),
     State('anomaly-threshold', 'value')],
    prevent_initial_call=True
)
def download_analysis_results(n_clicks, selection_pairs, original_json, transformed_json, anomaly_threshold):
    """Generate and download analysis results in Excel format"""
    if not n_clicks:
        return None
        
    try:
        original_df = pd.read_json(original_json, orient='split')
        transformed_df = pd.read_json(transformed_json, orient='split')
        
        cat_pairs = selection_pairs.get('categorical', [])
        num_pairs = selection_pairs.get('numerical', [])
        
        categorical_columns = [pair['source'] for pair in cat_pairs]
        categorical_matches = [pair['transformed'] for pair in cat_pairs]
        numerical_columns = [pair['source'] for pair in num_pairs]
        numerical_matches = [pair['transformed'] for pair in num_pairs]
        
        available_cat_original = [col for col in categorical_columns if col in original_df.columns]
        available_cat_transformed = [col for col in categorical_matches if col and col in transformed_df.columns]
        available_num_original = [col for col in numerical_columns if col in original_df.columns]
        available_num_transformed = [col for col in numerical_matches if col and col in transformed_df.columns]
        
        analysis_results = []
        
        # Perform analysis for each numerical pair
        for orig_num_col, trans_num_col in zip(available_num_original, available_num_transformed):
            if available_cat_original and available_cat_transformed:
                original_grouped = original_df.groupby(available_cat_original)[orig_num_col].sum().reset_index()
                transformed_grouped = transformed_df.groupby(available_cat_transformed)[trans_num_col].sum().reset_index()
                
                original_grouped.columns = [f"orig_{col}" if col != orig_num_col else "orig_sum" for col in original_grouped.columns]
                transformed_grouped.columns = [f"trans_{col}" if col != trans_num_col else "trans_sum" for col in transformed_grouped.columns]
                
                comparison_df = pd.merge(original_grouped, transformed_grouped,
                                       left_on=[f"orig_{col}" for col in available_cat_original],
                                       right_on=[f"trans_{col}" for col in available_cat_transformed],
                                       how='outer')
                
                comparison_df['percentage_diff'] = np.where(
                    (comparison_df['orig_sum'].notna()) & (comparison_df['trans_sum'].notna()),
                    abs(comparison_df['orig_sum'] - comparison_df['trans_sum']) / comparison_df['orig_sum'] * 100,
                    np.nan
                )
                
                analysis_results.append({
                    'numerical_column': f"{orig_num_col} → {trans_num_col}",
                    'comparison_data': comparison_df
                })
        
        # Generate Excel file
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            for idx, result in enumerate(analysis_results):
                if 'comparison_data' in result:
                    df = result['comparison_data'].copy()
                    df['Status'] = np.where(df['percentage_diff'] > anomaly_threshold,
                                          'Anomaly', 'No Anomaly')
                    sheet_name = f"Analysis_{idx+1}_{result['numerical_column']}"[:31]  # Excel sheet names limited to 31 chars
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        output.seek(0)
        return dcc.send_bytes(
            output.getvalue(),
            f"reconciliation_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        )
    
    except Exception as e:
        logger.error(f"Error generating download file: {str(e)}")
        return None

@app.callback(
    [Output('categorical-matches-text', 'children'),
     Output('numerical-matches-text', 'children')],
    [Input('categorical-source', 'value'),
     Input('numerical-source', 'value')],
    [State('original-data-store', 'data'),
     State('transformed-data-store', 'data')]
)
def update_matches_text(cat_source_cols, num_source_cols, original_json, transformed_json):
    """Update the text showing possible matches and their similarity scores"""
    if not original_json or not transformed_json:
        return "", ""
        
    original_df = pd.read_json(original_json, orient='split')
    transformed_df = pd.read_json(transformed_json, orient='split')
    
    cat_text = []
    num_text = []
    
    if cat_source_cols:
        for col in cat_source_cols:
            matches = find_matching_columns(original_df[col], transformed_df, 'categorical')
            if matches:
                match_text = f"'{col}' matches: " + ", ".join(
                    [f"'{m[0]}' ({m[1]:.2f})" for m in matches]
                )
                cat_text.append(match_text)
    
    if num_source_cols:
        for col in num_source_cols:
            matches = find_matching_columns(original_df[col], transformed_df, 'numerical')
            if matches:
                match_text = f"'{col}' matches: " + ", ".join(
                    [f"'{m[0]}' ({m[1]:.2f})" for m in matches]
                )
                num_text.append(match_text)
    
    cat_result = html.Div([html.P(text) for text in cat_text]) if cat_text else ""
    num_result = html.Div([html.P(text) for text in num_text]) if num_text else ""
    
    return cat_result, num_result

def generate_excel_from_results(analysis_results, anomaly_threshold):
    """Generate Excel file from analysis results"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        for idx, result in enumerate(analysis_results):
            if 'comparison_data' in result:
                df = result['comparison_data'].copy()
                # Add anomaly status column
                df['Status'] = np.where(df['percentage_diff'] > anomaly_threshold, 
                                      'Anomaly', 'No Anomaly')
                sheet_name = f"Analysis_{idx+1}"[:31]  # Excel sheet names limited to 31 chars
                df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    output.seek(0)
    return output

if __name__ == '__main__':
    app.run_server(debug=True, port=8050)
