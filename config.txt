def expand_dict_metrics_optimized(df, key_mapping=None, keys_to_include=None):
    """
    Optimized version using pandas operations.
    """
    # Separate numeric and dictionary rows
    date_cols = [col for col in df.columns if col != 'metric']
    
    # Identify rows with dictionaries
    has_dict_mask = df[date_cols].applymap(lambda x: isinstance(x, dict)).any(axis=1)
    
    numeric_df = df[~has_dict_mask].copy()
    dict_df = df[has_dict_mask].copy()
    
    # Process dictionary rows
    expanded_data = []
    
    for _, row in dict_df.iterrows():
        # Collect all unique keys from all date columns
        all_keys = set()
        for col in date_cols:
            if isinstance(row[col], dict):
                all_keys.update(row[col].keys())
        
        # Create rows for each key
        for key in all_keys:
            if keys_to_include and key not in keys_to_include:
                continue
                
            new_key = key_mapping.get(key, key) if key_mapping else key
            
            new_row = {'metric': new_key}
            for col in date_cols:
                if isinstance(row[col], dict):
                    new_row[col] = row[col].get(key, np.nan)
                else:
                    new_row[col] = np.nan
            
            expanded_data.append(new_row)
    
    # Combine all data
    expanded_df = pd.DataFrame(expanded_data)
    final_df = pd.concat([numeric_df, expanded_df], ignore_index=True)
    
    # Remove duplicates
    final_df = final_df.drop_duplicates(subset=['metric'], keep='first')
    
    return final_df.reset_index(drop=True)
